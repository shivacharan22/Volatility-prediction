{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fitting-composer",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-21T07:36:58.434349Z",
     "iopub.status.busy": "2021-09-21T07:36:58.433848Z",
     "iopub.status.idle": "2021-09-21T07:37:00.544991Z",
     "shell.execute_reply": "2021-09-21T07:37:00.544428Z",
     "shell.execute_reply.started": "2021-09-21T07:35:10.340035Z"
    },
    "papermill": {
     "duration": 2.133843,
     "end_time": "2021-09-21T07:37:00.545138",
     "exception": false,
     "start_time": "2021-09-21T07:36:58.411295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastai.layers import SigmoidRange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-supply",
   "metadata": {
    "papermill": {
     "duration": 0.022311,
     "end_time": "2021-09-21T07:37:00.585620",
     "exception": false,
     "start_time": "2021-09-21T07:37:00.563309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becoming-spokesman",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T07:37:00.636766Z",
     "iopub.status.busy": "2021-09-21T07:37:00.635826Z",
     "iopub.status.idle": "2021-09-21T07:37:00.638882Z",
     "shell.execute_reply": "2021-09-21T07:37:00.639528Z",
     "shell.execute_reply.started": "2021-09-21T07:35:11.070736Z"
    },
    "papermill": {
     "duration": 0.037221,
     "end_time": "2021-09-21T07:37:00.639801",
     "exception": false,
     "start_time": "2021-09-21T07:37:00.602580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmspe_metric(y_true, y_pred):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate root mean squared percentage error between ground-truth and predictions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true [array-like of shape (n_samples)]: Ground-truth\n",
    "    y_pred [array-like of shape (n_samples)]: Predictions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rmspe (float): Root mean squared percentage error\n",
    "    \"\"\"\n",
    "\n",
    "    rmspe = np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "    return rmspe\n",
    "\n",
    "\n",
    "def evaluate_predictions(predictions_column, evaluate_stock=False):\n",
    "    \n",
    "    for fold in sorted(df_train['fold'].unique()):\n",
    "\n",
    "        _, val_idx = df_train.loc[df_train['fold'] != fold].index, df_train.loc[df_train['fold'] == fold].index\n",
    "        fold_score = rmspe_metric(df_train.loc[val_idx, 'target'], df_train.loc[val_idx, predictions_column])\n",
    "        print(f'Fold {fold} - RMSPE: {fold_score:.6}')\n",
    "\n",
    "    oof_score = rmspe_metric(df_train['target'], df_train[predictions_column])\n",
    "    print(f'{\"-\" * 30}\\nOOF RMSPE: {oof_score:.6}\\n{\"-\" * 30}')\n",
    "\n",
    "    if evaluate_stock:\n",
    "        for stock_id in df_train['stock_id'].unique():\n",
    "            df_stock = df_train.loc[df_train['stock_id'] == stock_id, :]\n",
    "            stock_oof_score = rmspe_metric(df_stock['target'], df_stock[predictions_column])\n",
    "            print(f'Stock {stock_id} - OOF RMSPE: {stock_oof_score:.6}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-bosnia",
   "metadata": {
    "papermill": {
     "duration": 0.017335,
     "end_time": "2021-09-21T07:37:00.676907",
     "exception": false,
     "start_time": "2021-09-21T07:37:00.659572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radio-words",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T07:37:00.719989Z",
     "iopub.status.busy": "2021-09-21T07:37:00.719248Z",
     "iopub.status.idle": "2021-09-21T07:37:00.722296Z",
     "shell.execute_reply": "2021-09-21T07:37:00.723233Z",
     "shell.execute_reply.started": "2021-09-21T07:35:12.955305Z"
    },
    "papermill": {
     "duration": 0.029442,
     "end_time": "2021-09-21T07:37:00.723422",
     "exception": false,
     "start_time": "2021-09-21T07:37:00.693980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PreprocessingPipeline:\n",
    "    \n",
    "    def __init__(self, df_train, df_test):\n",
    "        \n",
    "        self.df_train = df_train.copy(deep=True)\n",
    "        self.df_test = df_test.copy(deep=True)\n",
    "        \n",
    "    def _label_encode(self):\n",
    "\n",
    "        # Encoding stock_id for embeddings\n",
    "        le = LabelEncoder()\n",
    "        self.df_train['stock_id_encoded'] = le.fit_transform(self.df_train['stock_id'].values)\n",
    "        self.df_test['stock_id_encoded'] = le.transform(self.df_test['stock_id'].values)\n",
    "    \n",
    "    def _get_folds(self):\n",
    "        \n",
    "        # Load pre-computed folds\n",
    "        self.df_train['fold'] = pd.read_csv('../input/optiver-realized-volatility-dataset/folds.csv')['fold_group']\n",
    "        self.df_train['fold'] = self.df_train['fold'].astype(np.uint8)\n",
    "        \n",
    "    def transform(self):\n",
    "        \n",
    "        self._label_encode()\n",
    "        self._get_folds()\n",
    "        \n",
    "        return self.df_train, self.df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "armed-berry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T07:37:00.769288Z",
     "iopub.status.busy": "2021-09-21T07:37:00.768537Z",
     "iopub.status.idle": "2021-09-21T07:37:01.276256Z",
     "shell.execute_reply": "2021-09-21T07:37:01.275536Z",
     "shell.execute_reply.started": "2021-09-21T07:35:13.991811Z"
    },
    "papermill": {
     "duration": 0.534659,
     "end_time": "2021-09-21T07:37:01.276495",
     "exception": false,
     "start_time": "2021-09-21T07:37:00.741836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape: (428932, 5) - Memory Usage: 8.18 MB\n",
      "Test Set Shape: (1, 3) - Memory Usage: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "train_test_dtypes = {\n",
    "    'stock_id': np.uint8,\n",
    "    'time_id': np.uint16,\n",
    "    'target': np.float64\n",
    "}\n",
    "\n",
    "df_train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv', dtype=train_test_dtypes)\n",
    "df_test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv', usecols=['stock_id', 'time_id'], dtype=train_test_dtypes)\n",
    "\n",
    "# Using only first row of test set if it is the placeholder\n",
    "# Other rows break the pipeline since some of the time buckets don't exist in book data\n",
    "if df_test.shape[0] == 3:\n",
    "    df_test = df_test.head(1)\n",
    "\n",
    "preprocessing_pipeline = PreprocessingPipeline(df_train, df_test)\n",
    "df_train, df_test = preprocessing_pipeline.transform()\n",
    "\n",
    "print(f'Training Set Shape: {df_train.shape} - Memory Usage: {df_train.memory_usage().sum() / 1024 ** 2:.2f} MB')\n",
    "print(f'Test Set Shape: {df_test.shape} - Memory Usage: {df_test.memory_usage().sum() / 1024 ** 2:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-hello",
   "metadata": {
    "papermill": {
     "duration": 0.018264,
     "end_time": "2021-09-21T07:37:01.315060",
     "exception": false,
     "start_time": "2021-09-21T07:37:01.296796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "satellite-compilation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T07:37:01.368125Z",
     "iopub.status.busy": "2021-09-21T07:37:01.367203Z",
     "iopub.status.idle": "2021-09-21T07:37:01.418835Z",
     "shell.execute_reply": "2021-09-21T07:37:01.419818Z",
     "shell.execute_reply.started": "2021-09-21T07:35:15.468965Z"
    },
    "papermill": {
     "duration": 0.086499,
     "end_time": "2021-09-21T07:37:01.420015",
     "exception": false,
     "start_time": "2021-09-21T07:37:01.333516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conv1dBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, skip_connection=False):\n",
    "\n",
    "        super(Conv1dBlock, self).__init__()\n",
    "\n",
    "        self.skip_connection = skip_connection\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(kernel_size,),\n",
    "                stride=(stride,),\n",
    "                padding=(kernel_size // 2,),\n",
    "                padding_mode='replicate',\n",
    "                bias=True\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(1,),\n",
    "                stride=(stride,),\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        output = self.conv_block(x)\n",
    "        if self.skip_connection:\n",
    "            x = self.downsample(x)\n",
    "            output += x\n",
    "        output = self.relu(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class Conv1dLayers(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, depth_scale, width_scale, skip_connection, initial=False):\n",
    "\n",
    "        super(Conv1dLayers, self).__init__()\n",
    "\n",
    "        depth = int(math.ceil(2 * depth_scale))\n",
    "        width = int(math.ceil(out_channels * width_scale))\n",
    "\n",
    "        if initial:\n",
    "            layers = [\n",
    "                Conv1dBlock(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=width,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=2,\n",
    "                    skip_connection=skip_connection\n",
    "                )\n",
    "            ]\n",
    "        else:\n",
    "            layers = [\n",
    "                Conv1dBlock(\n",
    "                    in_channels=(int(math.ceil(in_channels * width_scale))),\n",
    "                    out_channels=width,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=2,\n",
    "                    skip_connection=skip_connection\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        for _ in range(depth - 1):\n",
    "            layers += [\n",
    "                Conv1dBlock(\n",
    "                    in_channels=width,\n",
    "                    out_channels=width,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=1,\n",
    "                    skip_connection=skip_connection\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_layers(x)\n",
    "    \n",
    "\n",
    "class NonLocalBlock1d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, inter_channels=None, mode='embedded'):\n",
    "\n",
    "        super(NonLocalBlock1d, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "\n",
    "        self.g = nn.Conv1d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.inter_channels,\n",
    "            kernel_size=(1,),\n",
    "            stride=(1,),\n",
    "            padding=0\n",
    "        )\n",
    "        self.W_z = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.inter_channels,\n",
    "                out_channels=self.in_channels,\n",
    "                kernel_size=(1,),\n",
    "                stride=(1,),\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.BatchNorm1d(self.in_channels)\n",
    "        )\n",
    "        nn.init.constant_(self.W_z[1].weight, 0)\n",
    "        nn.init.constant_(self.W_z[1].bias, 0)\n",
    "\n",
    "        if self.mode == 'embedded' or self.mode == 'dot' or self.mode == 'concatenate':\n",
    "\n",
    "            self.theta = nn.Conv1d(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=self.inter_channels,\n",
    "                kernel_size=(1,),\n",
    "                stride=(1,),\n",
    "                padding=0\n",
    "            )\n",
    "            self.phi = nn.Conv1d(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=self.inter_channels,\n",
    "                kernel_size=(1,),\n",
    "                stride=(1,),\n",
    "                padding=0\n",
    "            )\n",
    "\n",
    "        if self.mode == 'concatenate':\n",
    "\n",
    "            self.W_f = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.inter_channels * 2,\n",
    "                    out_channels=1,\n",
    "                    kernel_size=(1, 1),\n",
    "                    stride=(1, 1),\n",
    "                    padding=0,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        if self.mode == 'gaussian':\n",
    "\n",
    "            theta_x = x.view(batch_size, self.in_channels, -1)\n",
    "            phi_x = x.view(batch_size, self.in_channels, -1)\n",
    "            theta_x = theta_x.permute(0, 2, 1)\n",
    "            f = torch.matmul(theta_x, phi_x)\n",
    "\n",
    "        elif self.mode == 'embedded' or self.mode == 'dot':\n",
    "\n",
    "            theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "            phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "            theta_x = theta_x.permute(0, 2, 1)\n",
    "            f = torch.matmul(theta_x, phi_x)\n",
    "\n",
    "        elif self.mode == 'concatenate':\n",
    "\n",
    "            theta_x = self.theta(x).view(batch_size, self.inter_channels, -1, 1)\n",
    "            phi_x = self.phi(x).view(batch_size, self.inter_channels, 1, -1)\n",
    "            h = theta_x.size(2)\n",
    "            w = phi_x.size(3)\n",
    "            theta_x = theta_x.repeat(1, 1, 1, w)\n",
    "            phi_x = phi_x.repeat(1, 1, h, 1)\n",
    "            concat = torch.cat([theta_x, phi_x], dim=1)\n",
    "            f = self.W_f(concat)\n",
    "            f = f.view(f.size(0), f.size(2), f.size(3))\n",
    "\n",
    "        if self.mode == 'gaussian' or self.mode == 'embedded':\n",
    "            f_div_C = F.softmax(f, dim=-1)\n",
    "        elif self.mode == 'dot' or self.mode == 'concatenate':\n",
    "            N = f.size(-1)\n",
    "            f_div_C = f / N\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "\n",
    "        W_y = self.W_z(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, use_stock_id, stock_embedding_dims, alpha, beta, phi):\n",
    "\n",
    "        super(CNN1DModel, self).__init__()\n",
    "\n",
    "        # Stock embeddings\n",
    "        self.use_stock_id = use_stock_id\n",
    "        self.stock_embedding_dims = stock_embedding_dims\n",
    "        self.stock_embeddings = nn.Embedding(num_embeddings=113, embedding_dim=self.stock_embedding_dims)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        # Model scaling\n",
    "        depth_scale = alpha ** phi\n",
    "        width_scale = beta ** phi\n",
    "        self.out_channels = int(math.ceil(out_channels * width_scale))\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv_layers1 = Conv1dLayers(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=32,\n",
    "            kernel_size=5,\n",
    "            depth_scale=depth_scale,\n",
    "            width_scale=width_scale,\n",
    "            skip_connection=False,\n",
    "            initial=True\n",
    "        )\n",
    "        self.conv_layers2 = Conv1dLayers(\n",
    "            in_channels=32,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            depth_scale=depth_scale,\n",
    "            width_scale=width_scale,\n",
    "            skip_connection=False,\n",
    "            initial=False\n",
    "        )\n",
    "        self.conv_layers3 = Conv1dLayers(\n",
    "            in_channels=64,\n",
    "            out_channels=128,\n",
    "            kernel_size=9,\n",
    "            depth_scale=depth_scale,\n",
    "            width_scale=width_scale,\n",
    "            skip_connection=False,\n",
    "            initial=False\n",
    "        )\n",
    "        self.conv_layers4 = Conv1dLayers(\n",
    "            in_channels=128,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=11,\n",
    "            depth_scale=depth_scale,\n",
    "            width_scale=width_scale,\n",
    "            skip_connection=False,\n",
    "            initial=False\n",
    "        )\n",
    "        \n",
    "        # Non-local blocks\n",
    "        self.nl_block1 = NonLocalBlock1d(in_channels=32, mode='embedded')\n",
    "        self.nl_block2 = NonLocalBlock1d(in_channels=64, mode='embedded')\n",
    "        self.nl_block3 = NonLocalBlock1d(in_channels=128, mode='embedded')\n",
    "        self.nl_block4 = NonLocalBlock1d(in_channels=self.out_channels, mode='embedded')\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(256 + self.stock_embedding_dims, 1, bias=True),\n",
    "            SigmoidRange(0, 0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, stock_ids, sequences):\n",
    "\n",
    "        x = torch.transpose(sequences, 1, 2)\n",
    "        x = self.conv_layers1(x)\n",
    "        x = self.nl_block1(x)\n",
    "        x = self.conv_layers2(x)\n",
    "        x = self.nl_block2(x)\n",
    "        x = self.conv_layers3(x)\n",
    "        x = self.nl_block3(x)\n",
    "        x = self.conv_layers4(x)\n",
    "        x = self.nl_block4(x)\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, x.shape[1])\n",
    "\n",
    "        if self.use_stock_id:\n",
    "            embedded_stock_ids = self.stock_embeddings(stock_ids)\n",
    "            x = torch.cat([x, self.dropout(embedded_stock_ids)], dim=1)\n",
    "\n",
    "        output = self.head(x)\n",
    "        return output.view(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-racing",
   "metadata": {
    "papermill": {
     "duration": 0.018213,
     "end_time": "2021-09-21T07:37:01.457840",
     "exception": false,
     "start_time": "2021-09-21T07:37:01.439627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "clear-stretch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T07:37:01.507965Z",
     "iopub.status.busy": "2021-09-21T07:37:01.507179Z",
     "iopub.status.idle": "2021-09-21T07:37:01.519307Z",
     "shell.execute_reply": "2021-09-21T07:37:01.520230Z",
     "shell.execute_reply.started": "2021-09-21T07:35:16.446708Z"
    },
    "papermill": {
     "duration": 0.044047,
     "end_time": "2021-09-21T07:37:01.520417",
     "exception": false,
     "start_time": "2021-09-21T07:37:01.476370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, attention_size):\n",
    "\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        self.attention_weights = nn.Parameter(torch.FloatTensor(attention_size))\n",
    "        nn.init.uniform_(self.attention_weights.data, -0.005, 0.005)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        attentions = self.relu(x.matmul(self.attention_weights))\n",
    "        attentions = self.softmax(attentions)\n",
    "        weighted = torch.mul(x, attentions.unsqueeze(-1).expand_as(x))\n",
    "        representations = weighted.sum(1).squeeze()\n",
    "\n",
    "        return representations, attentions\n",
    "\n",
    "    \n",
    "class RNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, use_stock_id, stock_embedding_dims):\n",
    "\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        # Stock embeddings\n",
    "        self.use_stock_id = use_stock_id\n",
    "        self.stock_embedding_dims = stock_embedding_dims\n",
    "        self.stock_embeddings = nn.Embedding(num_embeddings=113, embedding_dim=self.stock_embedding_dims)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        # Recurrent neural network\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0,\n",
    "            bidirectional=False,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Sequence self attention\n",
    "        self.attention = SelfAttention(attention_size=self.hidden_size)\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size + self.stock_embedding_dims, 1, bias=True),\n",
    "            SigmoidRange(0, 0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, stock_ids, sequences):\n",
    "        \n",
    "        h_n0 = torch.zeros(self.num_layers, sequences.size(0), self.hidden_size).to(self.device)\n",
    "        gru_output, h_n = self.gru(sequences, h_n0)\n",
    "        representations, attentions = self.attention(gru_output)\n",
    "\n",
    "        if self.use_stock_id:\n",
    "            embedded_stock_ids = self.stock_embeddings(stock_ids)\n",
    "            x = torch.cat([representations.view(1, -1), self.dropout(embedded_stock_ids)], dim=1)\n",
    "\n",
    "        output = self.head(x)\n",
    "        return output.view(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-summary",
   "metadata": {
    "papermill": {
     "duration": 0.021206,
     "end_time": "2021-09-21T07:37:01.560770",
     "exception": false,
     "start_time": "2021-09-21T07:37:01.539564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "posted-essex",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T07:37:01.613128Z",
     "iopub.status.busy": "2021-09-21T07:37:01.612221Z",
     "iopub.status.idle": "2021-09-21T07:37:08.167399Z",
     "shell.execute_reply": "2021-09-21T07:37:08.166762Z",
     "shell.execute_reply.started": "2021-09-21T07:35:39.327837Z"
    },
    "papermill": {
     "duration": 6.587362,
     "end_time": "2021-09-21T07:37:08.167559",
     "exception": false,
     "start_time": "2021-09-21T07:37:01.580197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN1D Models\n",
      "------------\n",
      "Loading model ../input/optiver-realized-volatility-dataset/cnn1d/cnn1d_fold1.pt into memory\n",
      "Loading model ../input/optiver-realized-volatility-dataset/cnn1d/cnn1d_fold2.pt into memory\n",
      "Loading model ../input/optiver-realized-volatility-dataset/cnn1d/cnn1d_fold3.pt into memory\n",
      "Loading model ../input/optiver-realized-volatility-dataset/cnn1d/cnn1d_fold4.pt into memory\n",
      "Loading model ../input/optiver-realized-volatility-dataset/cnn1d/cnn1d_fold5.pt into memory\n",
      "\n",
      "RNN Models\n",
      "----------\n",
      "Loading model ../input/optiver-realized-volatility-dataset/rnn/rnn_fold1.pt into memory\n",
      "Loading model ../input/optiver-realized-volatility-dataset/rnn/rnn_fold2.pt into memory\n",
      "Loading model ../input/optiver-realized-volatility-dataset/rnn/rnn_fold3.pt into memory\n",
      "Loading model ../input/optiver-realized-volatility-dataset/rnn/rnn_fold4.pt into memory\n",
      "Loading model ../input/optiver-realized-volatility-dataset/rnn/rnn_fold5.pt into memory\n"
     ]
    }
   ],
   "source": [
    "# Normalizing sequences with global means and stds\n",
    "book_means = np.array([\n",
    "    # Raw sequences\n",
    "    0.99969482421875, 1.000321388244629, 0.9995064735412598, 1.0005191564559937,\n",
    "    769.990177708821, 766.7345672818379, 959.3416027831918, 928.2202512713748,\n",
    "    # Absolute log returns of raw sequences\n",
    "    5.05890857311897e-05, 5.1026330766035244e-05, 5.74059049540665e-05, 5.8218309277435765e-05,\n",
    "    0.3967152245253066, 0.39100519899866804, 0.3239659116907835, 0.31638538484106116,\n",
    "    # Weighted average prices\n",
    "    1.0000068043192514, 1.0000055320253616, 1.000006872969592,\n",
    "    # Absolute log returns of weighted average prices\n",
    "    8.211420490291096e-05, 0.00011112522790786203, 8.236187150264073e-05\n",
    "])\n",
    "book_stds = np.array([\n",
    "    # Raw sequences\n",
    "    0.0036880988627672195, 0.003687119111418724, 0.0037009266670793295, 0.0036990800872445107,\n",
    "    5354.051690318169, 4954.947103063445, 6683.816183660414, 5735.299917793827,\n",
    "    # Absolute log returns of raw sequences\n",
    "    0.00016576898633502424, 0.00016801751917228103, 0.0001837657910073176, 0.0001868011022452265,\n",
    "    0.9121719707304721, 0.8988021131995019, 0.8415323589617927, 0.8244750862945265,\n",
    "    # Weighted average prices\n",
    "    0.003689893218043926, 0.00370745215558702, 0.0036913980961173682,\n",
    "    # Absolute log returns of weighted average prices\n",
    "    0.00021108155612872302, 0.00029320157822289604, 0.00019975085953727163\n",
    "])\n",
    "trade_means = np.array([0.999971866607666, 352.9736760331942, 4.1732040971227145])\n",
    "trade_stds = np.array([0.004607073962688446, 1041.9441951057488, 7.79955795393431])\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# CNN 1D\n",
    "cnn_parameters = {\n",
    "    'in_channels': 25,\n",
    "    'out_channels': 256,\n",
    "    'use_stock_id': True,\n",
    "    'stock_embedding_dims': 16,\n",
    "    'alpha': 1,\n",
    "    'beta': 1,\n",
    "    'phi': 1\n",
    "}\n",
    "\n",
    "print(f'CNN1D Models\\n{\"-\" * 12}')\n",
    "cnn_models = []\n",
    "for model_path in sorted(glob(f'../input/optiver-realized-volatility-dataset/cnn1d/*.pt')):\n",
    "    print(f'Loading model {model_path} into memory')\n",
    "    model = CNN1DModel(**cnn_parameters)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    cnn_models.append(model)\n",
    "    \n",
    "# RNN\n",
    "rnn_parameters = {\n",
    "    'input_size': 25,\n",
    "    'hidden_size': 64,\n",
    "    'num_layers': 3,\n",
    "    'use_stock_id': True,\n",
    "    'stock_embedding_dims': 16,\n",
    "}\n",
    "\n",
    "print(f'\\nRNN Models\\n{\"-\" * 10}')\n",
    "rnn_models = []\n",
    "for model_path in sorted(glob(f'../input/optiver-realized-volatility-dataset/rnn/*.pt')):\n",
    "    print(f'Loading model {model_path} into memory')\n",
    "    model = RNNModel(**rnn_parameters)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    rnn_models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "worse-request",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T07:37:08.200033Z",
     "iopub.status.busy": "2021-09-21T07:37:08.199547Z",
     "iopub.status.idle": "2021-09-21T07:37:09.039943Z",
     "shell.execute_reply": "2021-09-21T07:37:09.039318Z",
     "shell.execute_reply.started": "2021-09-21T07:35:54.240853Z"
    },
    "papermill": {
     "duration": 0.858603,
     "end_time": "2021-09-21T07:37:09.040095",
     "exception": false,
     "start_time": "2021-09-21T07:37:08.181492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN1D\n",
      "-----\n",
      "Fold 1 - RMSPE: 0.234049\n",
      "Fold 2 - RMSPE: 0.238894\n",
      "Fold 3 - RMSPE: 0.225608\n",
      "Fold 4 - RMSPE: 0.223012\n",
      "Fold 5 - RMSPE: 0.222544\n",
      "------------------------------\n",
      "OOF RMSPE: 0.228914\n",
      "------------------------------\n",
      "\n",
      "RNN\n",
      "---\n",
      "Fold 1 - RMSPE: 0.231432\n",
      "Fold 2 - RMSPE: 0.242344\n",
      "Fold 3 - RMSPE: 0.225047\n",
      "Fold 4 - RMSPE: 0.225377\n",
      "Fold 5 - RMSPE: 0.220146\n",
      "------------------------------\n",
      "OOF RMSPE: 0.228997\n",
      "------------------------------\n",
      "\n",
      "Blend\n",
      "-----\n",
      "Fold 1 - RMSPE: 0.230628\n",
      "Fold 2 - RMSPE: 0.238636\n",
      "Fold 3 - RMSPE: 0.223709\n",
      "Fold 4 - RMSPE: 0.221811\n",
      "Fold 5 - RMSPE: 0.219708\n",
      "------------------------------\n",
      "OOF RMSPE: 0.227004\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Loading pre-computed train predictions and evaluate them\n",
    "df_train['cnn1d_predictions'] = pd.read_csv('../input/optiver-realized-volatility-dataset/cnn1d/cnn1d_predictions.csv').values\n",
    "df_train['rnn_predictions'] = pd.read_csv('../input/optiver-realized-volatility-dataset/rnn/rnn_predictions.csv').values\n",
    "\n",
    "print(f'CNN1D\\n{\"-\" * 5}')\n",
    "evaluate_predictions('cnn1d_predictions')\n",
    "\n",
    "print(f'\\nRNN\\n{\"-\" * 3}')\n",
    "evaluate_predictions('rnn_predictions')\n",
    "\n",
    "print(f'\\nBlend\\n{\"-\" * 5}')\n",
    "df_train['blend_predictions'] = (df_train['cnn1d_predictions'] * 0.5) + (df_train['rnn_predictions'] * 0.5)\n",
    "evaluate_predictions('blend_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "helpful-beast",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T07:37:09.077487Z",
     "iopub.status.busy": "2021-09-21T07:37:09.072078Z",
     "iopub.status.idle": "2021-09-21T07:37:09.786280Z",
     "shell.execute_reply": "2021-09-21T07:37:09.785862Z",
     "shell.execute_reply.started": "2021-09-21T07:36:17.911146Z"
    },
    "papermill": {
     "duration": 0.731152,
     "end_time": "2021-09-21T07:37:09.786417",
     "exception": false,
     "start_time": "2021-09-21T07:37:09.055265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52f8856d589495ca43afcdd4815735d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "book_features = ['bid_price1', 'ask_price1', 'bid_price2', 'ask_price2','bid_size1', 'ask_size1', 'bid_size2', 'ask_size2']\n",
    "trade_features = ['price', 'size', 'order_count']\n",
    "stock_id_mapping = df_train.set_index('stock_id')['stock_id_encoded'].to_dict()\n",
    "\n",
    "for stock_id in tqdm(df_test['stock_id'].unique()):\n",
    "    \n",
    "    df_stock = df_test.loc[df_test['stock_id'] == stock_id]\n",
    "    df_book = pd.read_parquet(f'../input/optiver-realized-volatility-prediction/book_test.parquet/stock_id={stock_id}')\n",
    "    df_trade = pd.read_parquet(f'../input/optiver-realized-volatility-prediction/trade_test.parquet/stock_id={stock_id}')\n",
    "    stock_time_buckets = df_test.loc[df_test['stock_id'] == stock_id, 'time_id'].reset_index(drop=True)\n",
    "    missing_time_buckets = stock_time_buckets[~stock_time_buckets.isin(df_trade['time_id'])]\n",
    "    df_trade = df_trade.merge(missing_time_buckets, how='outer')\n",
    "    \n",
    "    # Iterating over time_ids\n",
    "    for time_id in df_stock['time_id'].unique():\n",
    "        \n",
    "        # Resample order book to 600 seconds, forward fill and back fill for edge cases\n",
    "        df_book_time_bucket = df_book.loc[df_book['time_id'] == time_id]\n",
    "        df_book_time_bucket = df_book_time_bucket.set_index(['seconds_in_bucket'])\n",
    "        df_book_time_bucket = df_book_time_bucket.reindex(np.arange(0, 600), method='ffill').fillna(method='bfill')\n",
    "        \n",
    "        # Sequences from book data\n",
    "        book_sequences = df_book_time_bucket.reset_index(drop=True)[book_features].values\n",
    "        \n",
    "        # Absolute log returns of raw sequences\n",
    "        book_bid_price1_log = np.log(book_sequences[:, 0])\n",
    "        book_bid_price1_absolute_log_returns = np.abs(np.diff(book_bid_price1_log, prepend=[book_bid_price1_log[0]]))\n",
    "        book_ask_price1_log = np.log(book_sequences[:, 1])\n",
    "        book_ask_price1_absolute_log_returns = np.abs(np.diff(book_ask_price1_log, prepend=[book_ask_price1_log[0]]))\n",
    "        book_bid_price2_log = np.log(book_sequences[:, 2])\n",
    "        book_bid_price2_absolute_log_returns = np.abs(np.diff(book_bid_price2_log, prepend=[book_bid_price2_log[0]]))\n",
    "        book_ask_price2_log = np.log(book_sequences[:, 3])\n",
    "        book_ask_price2_absolute_log_returns = np.abs(np.diff(book_ask_price2_log, prepend=[book_ask_price2_log[0]]))\n",
    "        book_bid_size1_log = np.log(book_sequences[:, 4])\n",
    "        book_bid_size1_absolute_log_returns = np.abs(np.diff(book_bid_size1_log, prepend=[book_bid_size1_log[0]]))\n",
    "        book_ask_size1_log = np.log(book_sequences[:, 5])\n",
    "        book_ask_size1_absolute_log_returns = np.abs(np.diff(book_ask_size1_log, prepend=[book_ask_size1_log[0]]))\n",
    "        book_bid_size2_log = np.log(book_sequences[:, 6])\n",
    "        book_bid_size2_absolute_log_returns = np.abs(np.diff(book_bid_size2_log, prepend=[book_bid_size2_log[0]]))\n",
    "        book_ask_size2_log = np.log(book_sequences[:, 7])\n",
    "        book_ask_size2_absolute_log_returns = np.abs(np.diff(book_ask_size2_log, prepend=[book_ask_size2_log[0]]))\n",
    "\n",
    "        # Weighted average prices\n",
    "        book_wap1 = (book_sequences[:, 0] * book_sequences[:, 5] + book_sequences[:, 1] * book_sequences[:, 4]) /\\\n",
    "                    (book_sequences[:, 4] + book_sequences[:, 5])\n",
    "        book_wap2 = (book_sequences[:, 2] * book_sequences[:, 7] + book_sequences[:, 3] * book_sequences[:, 6]) /\\\n",
    "                    (book_sequences[:, 6] + book_sequences[:, 7])\n",
    "        book_wap3 = ((book_sequences[:, 0] * book_sequences[:, 5] + book_sequences[:, 1] * book_sequences[:, 4]) +\n",
    "                     (book_sequences[:, 2] * book_sequences[:, 7] + book_sequences[:, 3] * book_sequences[:, 6])) /\\\n",
    "                    (book_sequences[:, 4] + book_sequences[:, 5] + book_sequences[:, 6] + book_sequences[:, 7])\n",
    "\n",
    "        # Absolute log returns of weighted average prices\n",
    "        book_wap1_log = np.log(book_wap1)\n",
    "        book_wap1_absolute_log_returns = np.abs(np.diff(book_wap1_log, prepend=[book_wap1_log[0]]))\n",
    "        book_wap2_log = np.log(book_wap2)\n",
    "        book_wap2_absolute_log_returns = np.abs(np.diff(book_wap2_log, prepend=[book_wap2_log[0]]))\n",
    "        book_wap3_log = np.log(book_wap3)\n",
    "        book_wap3_absolute_log_returns = np.abs(np.diff(book_wap3_log, prepend=[book_wap3_log[0]]))\n",
    "\n",
    "        book_sequences = np.hstack([\n",
    "            book_sequences,\n",
    "            book_bid_price1_absolute_log_returns.reshape(-1, 1),\n",
    "            book_ask_price1_absolute_log_returns.reshape(-1, 1),\n",
    "            book_bid_price2_absolute_log_returns.reshape(-1, 1),\n",
    "            book_ask_price2_absolute_log_returns.reshape(-1, 1),\n",
    "            book_bid_size1_absolute_log_returns.reshape(-1, 1),\n",
    "            book_ask_size1_absolute_log_returns.reshape(-1, 1),\n",
    "            book_bid_size2_absolute_log_returns.reshape(-1, 1),\n",
    "            book_ask_size2_absolute_log_returns.reshape(-1, 1),\n",
    "            book_wap1.reshape(-1, 1),\n",
    "            book_wap2.reshape(-1, 1),\n",
    "            book_wap3.reshape(-1, 1),\n",
    "            book_wap1_absolute_log_returns.reshape(-1, 1),\n",
    "            book_wap2_absolute_log_returns.reshape(-1, 1),\n",
    "            book_wap3_absolute_log_returns.reshape(-1, 1),\n",
    "        ])\n",
    "        book_sequences = (book_sequences - book_means) / book_stds\n",
    "        \n",
    "        # Resample trade data to 600 seconds and fill missing values with 0\n",
    "        df_trade_time_bucket = df_trade.loc[df_trade['time_id'] == time_id]\n",
    "        df_trade_time_bucket = df_trade_time_bucket.set_index(['seconds_in_bucket'])\n",
    "        df_trade_time_bucket = df_trade_time_bucket.reindex(np.arange(0, 600)).fillna(0)\n",
    "        \n",
    "        # Sequences from trade data\n",
    "        trade_sequences = df_trade_time_bucket.reset_index(drop=True)[trade_features].values\n",
    "        # Not normalizing zero values in trade data\n",
    "        trade_sequences[trade_sequences[:, 0] != 0, :] = (trade_sequences[trade_sequences[:, 0] != 0, :] - trade_means) / trade_stds\n",
    "        \n",
    "        # Concatenate book and trade sequences\n",
    "        sequences = np.hstack([book_sequences, trade_sequences])\n",
    "        sequences = torch.as_tensor(sequences.reshape(1, 600, 25), dtype=torch.float)\n",
    "        sequences = sequences.to(device)\n",
    "        \n",
    "        stock_id_encoded = torch.as_tensor([stock_id_mapping[stock_id]], dtype=torch.long)\n",
    "        stock_id_encoded = stock_id_encoded.to(device)\n",
    "        \n",
    "        cnn_prediction = 0\n",
    "        for model in cnn_models:\n",
    "            with torch.no_grad():\n",
    "                cnn_model_prediction = model(stock_id_encoded, sequences).detach().cpu().numpy()\n",
    "                cnn_prediction += (cnn_model_prediction[0] / 5)\n",
    "        df_test.loc[(df_test['stock_id'] == stock_id) & (df_test['time_id'] == time_id), 'cnn1d_predictions'] = cnn_prediction\n",
    "                \n",
    "        rnn_prediction = 0\n",
    "        for model in rnn_models:\n",
    "            with torch.no_grad():\n",
    "                rnn_model_prediction = model(stock_id_encoded, sequences).detach().cpu().numpy()\n",
    "                rnn_prediction += (rnn_model_prediction[0] / 5)\n",
    "        df_test.loc[(df_test['stock_id'] == stock_id) & (df_test['time_id'] == time_id), 'rnn_predictions'] = rnn_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "overhead-maple",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T07:37:09.824768Z",
     "iopub.status.busy": "2021-09-21T07:37:09.822436Z",
     "iopub.status.idle": "2021-09-21T07:37:09.945664Z",
     "shell.execute_reply": "2021-09-21T07:37:09.944894Z",
     "shell.execute_reply.started": "2021-09-21T07:36:26.438669Z"
    },
    "papermill": {
     "duration": 0.144681,
     "end_time": "2021-09-21T07:37:09.945782",
     "exception": false,
     "start_time": "2021-09-21T07:37:09.801101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test['target'] = (df_test['cnn1d_predictions'] * 0.5) + (df_test['rnn_predictions'] * 0.5)\n",
    "df_test['row_id'] = df_test['stock_id'].astype(str) + '-' + df_test['time_id'].astype(str)\n",
    "df_test[['row_id', 'target']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "numerous-pathology",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-21T07:37:09.982494Z",
     "iopub.status.busy": "2021-09-21T07:37:09.981878Z",
     "iopub.status.idle": "2021-09-21T07:37:09.989106Z",
     "shell.execute_reply": "2021-09-21T07:37:09.988709Z",
     "shell.execute_reply.started": "2021-09-21T07:36:28.144581Z"
    },
    "papermill": {
     "duration": 0.028517,
     "end_time": "2021-09-21T07:37:09.989220",
     "exception": false,
     "start_time": "2021-09-21T07:37:09.960703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target\n",
       "0    0-4  0.001076"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['row_id', 'target']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.742036,
   "end_time": "2021-09-21T07:37:11.672347",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-21T07:36:51.930311",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0fdb316677c74afe94873debbc5a902a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3eafc5f038b34f519dcc2e8ae706944b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4b13508047534889b89f4696ac6ec5f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "66b8fa1358544e3cbffeacd23db4d50b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6adf3e3de8234b52bfefa8dcd092b9d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a8eb77a932e9480abd50fbd7492bbf33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_66b8fa1358544e3cbffeacd23db4d50b",
       "placeholder": "​",
       "style": "IPY_MODEL_d25836e90623424f9551c8b7bcb008b8",
       "value": " 1/1 [00:00&lt;00:00,  1.77it/s]"
      }
     },
     "ca082daf56f1429ca723c354503430b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ce665f7164c04127b82e65575bcd99b8",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6adf3e3de8234b52bfefa8dcd092b9d2",
       "value": 1.0
      }
     },
     "ce665f7164c04127b82e65575bcd99b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d25836e90623424f9551c8b7bcb008b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d52f8856d589495ca43afcdd4815735d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fa45d26881fc45a48dd99c9636a126f8",
        "IPY_MODEL_ca082daf56f1429ca723c354503430b1",
        "IPY_MODEL_a8eb77a932e9480abd50fbd7492bbf33"
       ],
       "layout": "IPY_MODEL_3eafc5f038b34f519dcc2e8ae706944b"
      }
     },
     "fa45d26881fc45a48dd99c9636a126f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4b13508047534889b89f4696ac6ec5f7",
       "placeholder": "​",
       "style": "IPY_MODEL_0fdb316677c74afe94873debbc5a902a",
       "value": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
